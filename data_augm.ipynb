{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be4f0b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "452d7515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from numpy import expand_dims\n",
    "from scipy.integrate import odeint,quad,dblquad,simps,quad_vec,nquad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d27ac14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import datasets, layers, models\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Conv2D, MaxPooling2D, Activation, concatenate\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from glob import glob \n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.io import imread\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from colorspacious import cspace_converter\n",
    "from collections import OrderedDict\n",
    "\n",
    "import pylab as py\n",
    "import threading\n",
    "import scipy\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from scipy import constants\n",
    "from scipy import interpolate\n",
    "from scipy import signal\n",
    "from scipy import ndimage\n",
    "from scipy.linalg import block_diag\n",
    "import sympy\n",
    "\n",
    "from matplotlib.image import imread\n",
    "import skimage\n",
    "from skimage.transform import rotate\n",
    "from skimage.io import imshow, show, imsave\n",
    "from skimage import img_as_ubyte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "249108e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the CSV Files of the \n",
    "train_labels = sorted(glob('/home/alex/ml_master/virt/master_ml/cnn_fourier/data_cnn/labels/label*.csv'))\n",
    "N_label = len(train_labels)\n",
    "# write header of csv file\n",
    "header = ['id','appliance']\n",
    "with open('data_cnn/header.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "\n",
    "# create dataset\n",
    "fout = open('data_cnn/labels.csv','w')\n",
    "\n",
    "for line in open('data_cnn/header.csv'):\n",
    "    fout.write(line)\n",
    "\n",
    "for i in range(N_label):\n",
    "    file = open(train_labels[i])\n",
    "#     file.__next__()\n",
    "    for line in file:\n",
    "        fout.write(line)\n",
    "    file.close()\n",
    "fout.close()\n",
    "# ######### weg got our dataset train_labels ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e523d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the Dataset we created without data augmentation ####\n",
    "train_df_aug = pd.read_csv('data_cnn/labels.csv', index_col=0)\n",
    "train_df_aug['id'] = train_df_aug.index.map(lambda id: id)\n",
    "train_df_aug['amplitude'] = train_df_aug.index.map(lambda id: f'data_cnn/target/{id}_ampl.png')\n",
    "train_df_aug['phase'] = train_df_aug.index.map(lambda id: f'data_cnn/target/{id}_phase.png')\n",
    "# print(len(train_df))\n",
    "# ftraindf = open('data_cnn/train_df.csv','a')\n",
    "# ftraindf.write(train_df)\n",
    "len(train_df_aug.amplitude.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "831a1f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_df_aug)):\n",
    "    phase_aug = imread(train_df_aug.phase.values[i]) ## read the train images (ampl,phase)\n",
    "    ampl_aug = imread(train_df_aug.amplitude.values[i])\n",
    "    id_aug = train_df_aug.id[i] \n",
    "    appl_aug = train_df_aug.appliance[i] ## read id and appliance to correlate\n",
    "    \n",
    "    ### rotate the images (ampl,phase) and save them\n",
    "    for k in range(3):\n",
    "        sess = tf.InteractiveSession()\n",
    "        phase_rot1 = tf.contrib.image.rotate(phase_aug, 90*(k+1)*np.pi/180, interpolation='bilinear')\n",
    "        phase_rot1 = phase_rot1.eval() ## rotate the image\n",
    "        ampl_rot1 = tf.contrib.image.rotate(ampl_aug, 90*(k+1)*np.pi/180, interpolation='bilinear')\n",
    "        ampl_rot1 = ampl_rot1.eval()\n",
    "\n",
    "        imsave('data_cnn/target_aug/'+id_aug+'_rot'+str(k)+'_ampl.png', img_as_ubyte(ampl_rot1)) ##save the images in the train file\n",
    "        imsave('data_cnn/target_aug/'+id_aug+'_rot'+str(k)+'_phase.png', img_as_ubyte(phase_rot1))\n",
    "    \n",
    "    \n",
    "        label_aug = [id_aug+'_rot'+str(k),  appl_aug]\n",
    "        with open(('/home/alex/ml_master/virt/master_ml/cnn_fourier/data_cnn/label_aug/label_'+id_aug+'_rot'+str(k)+'.csv'), 'w') as fid:\n",
    "            writer = csv.writer(fid)\n",
    "            writer.writerow(label_aug) ## write the correlated labels for the augmented data images\n",
    "    \n",
    "    \n",
    "    sess = tf.InteractiveSession()\n",
    "    phase_flip_1 = tf.image.flip_left_right(phase_aug)\n",
    "    phase_flip_1 = phase_flip_1.eval()\n",
    "    ampl_flip_1 = tf.image.flip_left_right(ampl_aug)\n",
    "    ampl_flip_1 = ampl_flip_1.eval()\n",
    "    phase_flip_2 = tf.image.flip_up_down(phase_aug)\n",
    "    phase_flip_2 = phase_flip_2.eval()\n",
    "    ampl_flip_2 = tf.image.flip_up_down(ampl_aug)\n",
    "    ampl_flip_2 = ampl_flip_2.eval()\n",
    "    \n",
    "    \n",
    "    imsave('data_cnn/target_aug/'+id_aug+'_flip_lr_ampl.png', img_as_ubyte(ampl_flip_1))\n",
    "    imsave('data_cnn/target_aug/'+id_aug+'_flip_ud_ampl.png', img_as_ubyte(ampl_flip_2))\n",
    "    \n",
    "    imsave('data_cnn/target_aug/'+id_aug+'_flip_lr_phase.png', img_as_ubyte(phase_flip_1))\n",
    "    imsave('data_cnn/target_aug/'+id_aug+'_flip_ud_phase.png', img_as_ubyte(phase_flip_2))\n",
    "    \n",
    "    \n",
    "       \n",
    "    label_flip_lr = [id_aug+'_flip_lr',  appl_aug]\n",
    "    with open(('/home/alex/ml_master/virt/master_ml/cnn_fourier/data_cnn/label_aug/label_'+id_aug+'_flip_lr.csv'), 'w') as fid:\n",
    "        writer = csv.writer(fid)\n",
    "        writer.writerow(label_flip_lr) ## write the correlated labels for the augmented data images\n",
    "                   \n",
    "    label_flip_ud = [id_aug+'_flip_ud',  appl_aug]\n",
    "    with open(('/home/alex/ml_master/virt/master_ml/cnn_fourier/data_cnn/label_aug/label_'+id_aug+'_flip_ud.csv'), 'w') as fid2:\n",
    "        writer = csv.writer(fid2)\n",
    "        writer.writerow(label_flip_ud) ## write the correlated labels for the augmented data images\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66b8ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the CSV Files of the \n",
    "train_labels = sorted(glob('/home/alex/ml_master/virt/master_ml/cnn_fourier/data_cnn/label_aug/label*.csv'))\n",
    "N_label = len(train_labels)\n",
    "# write header of csv file\n",
    "header = ['id','appliance']\n",
    "with open('data_cnn/header.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "\n",
    "# create dataset\n",
    "fout = open('data_cnn/labels.csv','w')\n",
    "\n",
    "for line in open('data_cnn/header.csv'):\n",
    "    fout.write(line)\n",
    "\n",
    "for i in range(N_label):\n",
    "    file = open(train_labels[i])\n",
    "#     file.__next__()\n",
    "    for line in file:\n",
    "        fout.write(line)\n",
    "    file.close()\n",
    "fout.close()\n",
    "# ######### weg got our dataset train_labels ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dbac4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ace6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dead25bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
