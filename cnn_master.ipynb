{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from numpy import expand_dims\n",
    "from scipy.integrate import odeint,quad,dblquad,simps,quad_vec,nquad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import datasets, layers, models\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Conv2D, MaxPooling2D, Activation, concatenate\n",
    "from keras.models import Sequential, save_model, load_model\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from glob import glob \n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.io import imread\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from colorspacious import cspace_converter\n",
    "from collections import OrderedDict\n",
    "\n",
    "import pylab as py\n",
    "import threading\n",
    "import scipy\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from scipy import constants\n",
    "from scipy import interpolate\n",
    "from scipy import signal\n",
    "from scipy import ndimage\n",
    "from scipy.linalg import block_diag\n",
    "import sympy\n",
    "\n",
    "from matplotlib.image import imread\n",
    "import skimage\n",
    "from skimage.transform import rotate\n",
    "from skimage.io import imshow, show, imsave\n",
    "from skimage import img_as_ubyte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read the Input dataset -> Fourier Data which should look like reconstructed afterwards ###\n",
    "input_df = pd.read_csv('data_cnn/labels.csv', index_col=0)\n",
    "input_df['id'] = input_df.index.map(lambda id: id)\n",
    "input_df['amplitude'] = input_df.index.map(lambda id: f'data_cnn/input_aug/{id}_ampl.png')\n",
    "input_df['phase'] = input_df.index.map(lambda id: f'data_cnn/input_aug/{id}_phase.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_paths, img_rows, img_cols,  channels):\n",
    "    \"\"\"\n",
    "      Reads the spectogram files from disk and normalizes the pixel values\n",
    "        @params:\n",
    "          file_paths - Array of file paths to read from\n",
    "          img_rows - The image height.\n",
    "          img_cols - The image width.\n",
    "          as_grey - Read the image as Greyscale or RGB.\n",
    "          channels - Number of channels.\n",
    "        @returns:\n",
    "          The created and compiled model (Model)        \n",
    "    \"\"\"\n",
    "    images = []\n",
    "  \n",
    "    for file_path in file_paths:\n",
    "        images.append(imread(file_path))\n",
    "    \n",
    "    images = np.asarray(images, dtype=np.float32)\n",
    "  \n",
    "  # normalize\n",
    "    images = images / 255.0 #np.max(images)\n",
    "  \n",
    "  # reshape to match Keras expectaions\n",
    "    images = images.reshape(images.shape[0], img_rows, img_cols, channels)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Hyper Parameters ####\n",
    "\n",
    "## pixel if images ##\n",
    "img_rows, img_cols = 120, 120\n",
    "as_gray=True\n",
    "in_channels = 3 # rgb files\n",
    "num_classes = 3 # number of charts\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "input_shape = (img_rows, img_cols, in_channels)\n",
    "input_img = Input(shape= input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 120, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read the images from CSV File ####\n",
    "\n",
    "x_train_amplitude=read_data(input_df.amplitude.values, img_rows, img_cols, in_channels)\n",
    "x_train_phase = read_data(input_df.phase.values, img_rows, img_cols, in_channels)\n",
    "\n",
    "# labels - convert class vectors to binary class matrices One Hot Encoding\n",
    "labels = input_df.appliance.values\n",
    "labels = keras.utils.to_categorical(labels, num_classes)\n",
    "\n",
    "np.shape(x_train_amplitude[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 120, 120, 3)\n"
     ]
    }
   ],
   "source": [
    "# split the train data for test batches\n",
    "\n",
    "x_train_comp = np.stack((x_train_amplitude, x_train_phase), axis=4)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train_comp, labels, test_size=0.25, random_state=666)\n",
    "\n",
    "# take them apart\n",
    "x_train_amplitude = x_train[:,:,:,:,0]\n",
    "x_test_amplitude = x_test[:,:,:,:,0]\n",
    "\n",
    "x_train_phase = x_train[:,:,:,:,1]\n",
    "x_test_phase = x_test[:,:,:,:,1]\n",
    "\n",
    "print(np.shape(x_train_phase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 120, 120, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_phase.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(x_train_amplitude, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convolution_layers(input_img):\n",
    "    \n",
    "    model = Conv2D(32, (3, 3), padding='same', input_shape=input_shape)(input_img)\n",
    "    model = LeakyReLU(alpha=0.1)(model)\n",
    "    model = MaxPooling2D((2, 2),padding='same')(model)\n",
    "    model = Dropout(0.25)(model)\n",
    "  \n",
    "    model = Conv2D(64, (3, 3), padding='same')(model)\n",
    "    model = LeakyReLU(alpha=0.1)(model)\n",
    "    model = MaxPooling2D(pool_size=(2, 2),padding='same')(model)\n",
    "    model = Dropout(0.25)(model)\n",
    "    \n",
    "    model = Conv2D(128, (3, 3), padding='same')(model)\n",
    "    model = LeakyReLU(alpha=0.1)(model)\n",
    "    model = MaxPooling2D(pool_size=(2, 2),padding='same')(model)\n",
    "    model = Dropout(0.4)(model)\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 120, 120, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 120, 120, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 120, 120, 32) 896         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 120, 120, 32) 896         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 120, 120, 32) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 120, 120, 32) 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 60, 60, 32)   0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 60, 60, 32)   0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 60, 60, 32)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 60, 60, 32)   0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 60, 60, 64)   18496       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 60, 60, 64)   18496       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 60, 60, 64)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 60, 60, 64)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 30, 30, 64)   0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 30, 30, 64)   0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 30, 30, 64)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 30, 30, 64)   0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 30, 30, 128)  73856       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 30, 30, 128)  73856       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 30, 30, 128)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 30, 30, 128)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 15, 15, 128)  0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 15, 15, 128)  0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 15, 15, 128)  0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 15, 15, 128)  0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 15, 15, 256)  0           dropout_3[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 57600)        0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          29491712    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 512)          0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            1539        dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 29,679,747\n",
      "Trainable params: 29,679,747\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ampl_input = Input(shape=input_shape)\n",
    "ampl_model = create_convolution_layers(ampl_input)\n",
    "\n",
    "phase_input = Input(shape=input_shape)\n",
    "phase_model = create_convolution_layers(phase_input)\n",
    "\n",
    "conv = concatenate([ampl_model, phase_model])\n",
    "\n",
    "conv = Flatten()(conv)\n",
    "\n",
    "dense = Dense(512)(conv)\n",
    "dense = LeakyReLU(alpha=0.1)(dense)\n",
    "dense = Dropout(0.5)(dense)\n",
    "\n",
    "output = Dense(num_classes, activation='softmax')(dense)\n",
    "\n",
    "model = Model(inputs=[ampl_input, phase_input], outputs=[output])\n",
    "\n",
    "opt = optimizers.Adam()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.summary()\n",
    "# np.shape(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Train the model###\n",
    "\n",
    "best_weights_file=\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(best_weights_file, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "\n",
    "history=model.fit([x_train_amplitude, x_train_phase], y_train,\n",
    "         batch_size=batch_size,\n",
    "         epochs=epochs,\n",
    "         callbacks=callbacks,\n",
    "         verbose=1,\n",
    "         validation_data=([x_test_amplitude, x_test_phase] ,y_test)\n",
    "         ,shuffle=True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='accuracy')\n",
    "plt.plot(history.history['val_acc'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.4, 1])\n",
    "plt.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "filepath = './saved_model'\n",
    "# save_model(model, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = load_model(filepath, compile = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "preds = model.evaluate([x_test_amplitude,x_test_phase],y_test)\n",
    "\n",
    "print ('Loss = ' + str(preds[0]))\n",
    "print ('Test Accuracy = ' + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict({'input_2':img_amp, 'input_3':img_ph})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
